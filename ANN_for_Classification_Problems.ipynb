{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1p6esqCyKiH_"
   },
   "source": [
    "<h1> Artificial Neural Networks for Classification Problems </h1>\n",
    "\n",
    "<p> Artificial Neural Networks (ANN), also known as neural networks or simulated neural networks (SNNs), are a subset of machine learning and are at the heart of deep learning algorithms. Their name and structure are inspired by the human brain, mimicking the way that biological neurons signal to one another. </p>\n",
    "\n",
    "<p> Artificial neural networks (ANNs) are comprised of a node layers, containing an input layer, one or more hidden layers, and an output layer. Each node, or artificial neuron, connects to another and has an associated weight and threshold. If the output of any individual node is above the specified threshold value, that node is activated, sending data to the next layer of the network. Otherwise, no data is passed along to the next layer of the network. </p>\n",
    "\n",
    "We will be using the following:\n",
    "* Python\n",
    "* Jupyter Notebook / Google Colab\n",
    "* Pandas\n",
    "* NumPy\n",
    "* Tensorflow\n",
    "* Scikit-Learn\n",
    "\n",
    "For our modeling, we will be using Churn modeling dataset from Kaggle. You can find it [here.](https://www.kaggle.com/datasets/shrutimechlearn/churn-modelling)\n",
    "\n",
    "The dataset contains the following attributes:\n",
    "* RowNumber: Represents the number of rows\n",
    "* CustomerId: Represents customerId\n",
    "* Surname: Represents surname of the customer\n",
    "* CreditScore: Represents credit score of the customer\n",
    "* Geography: Represents the city to which customers belongs to\n",
    "* Gender: Represents Gender of the customer\n",
    "* Age: Represents age of the customer\n",
    "* Tenure: Represents tenure of the customer with a bank\n",
    "* Balance: Represents balance hold by the customer\n",
    "* NumOfProducts: Represents the number of bank services used by the customer\n",
    "* HasCrCard: Represents if a customer has a credit card or not\n",
    "* IsActiveMember: Represents if a customer is an active member or not\n",
    "* EstimatedSalary: Represents estimated salary of the customer\n",
    "* Exited: Represents if a customer is going to exit the bank or not.\n",
    "\n",
    "<p> Our major objective here is to build an artificial neural network that will examine all independent factors (the first 13) and forecast whether or not our customer will leave the bank (Exited is dependent variable here). </p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "DcRQcpKJKeQb"
   },
   "outputs": [],
   "source": [
    "# Importing the necessary libraries \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 270
    },
    "id": "RKE_Z1V9O2bu",
    "outputId": "c37ce31d-e633-4c73-d06f-9c560c89a4bd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-30a46d6f-3139-443f-a58c-4761df02e53c\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-30a46d6f-3139-443f-a58c-4761df02e53c')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-30a46d6f-3139-443f-a58c-4761df02e53c button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-30a46d6f-3139-443f-a58c-4761df02e53c');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the data\n",
    "data = pd.read_csv('/content/sample_data/Churn_Modelling.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "_N6hFwtMPIFk"
   },
   "outputs": [],
   "source": [
    "# Declaring the independent and dependent variables \n",
    "X = data.iloc[:,3:-1].values \n",
    "y = data.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yUrcYrF6P1lY"
   },
   "source": [
    "Now that we have declared our X and y, we must perform some feature engineering to encode our categorical variables Gender and Country. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CJJGPHNpQQ7_",
    "outputId": "b4c9451d-6d5d-4d67-ec3d-6a8dcaf03018"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[619, 'France', 0, ..., 1, 1, 101348.88],\n",
       "       [608, 'Spain', 0, ..., 0, 1, 112542.58],\n",
       "       [502, 'France', 0, ..., 1, 0, 113931.57],\n",
       "       ...,\n",
       "       [709, 'France', 0, ..., 0, 1, 42085.58],\n",
       "       [772, 'Germany', 1, ..., 1, 0, 92888.52],\n",
       "       [792, 'France', 0, ..., 1, 0, 38190.78]], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encoding our categorical variable Gender using LabelEncoder()\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "LE1 = LabelEncoder()\n",
    "X[:,2] = np.array(LE1.fit_transform(X[:,2]))\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CtT-CKQeRJ2f",
    "outputId": "96042acd-909a-40b0-902e-891aa38ebe2f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['France', 'Spain', 'Germany'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let us now see how many unique countries are there in our dataset\n",
    "data['Geography'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DE3c7iZ6Q0ss"
   },
   "source": [
    "To encode our second categorical variable Country, we will be using one-hot encoding since there are 3 different categories of countries. In one hot encoding, all the string values are converted into binary streams of 0’s and 1’s. One-hot encoding ensures that the machine learning algorithm does not assume that higher numbers are more important.\n",
    "\n",
    "</br>\n",
    "\n",
    "We will be using ColumnTransformer for this encoding. This estimator allows different columns or column subsets of the input to be transformed separately and the features generated by each transformer will be concatenated to form a single feature space. This is useful for heterogeneous or columnar data, to combine several feature extraction mechanisms or transformations into a single transformer. You can find the documentation [here.]('https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KEtmaB2DRpJU",
    "outputId": "6efe9ecb-7713-49bc-98dc-0933c6ba5622"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0, 0.0, 0.0, ..., 1, 1, 101348.88],\n",
       "       [0.0, 0.0, 1.0, ..., 0, 1, 112542.58],\n",
       "       [1.0, 0.0, 0.0, ..., 1, 0, 113931.57],\n",
       "       ...,\n",
       "       [1.0, 0.0, 0.0, ..., 0, 1, 42085.58],\n",
       "       [0.0, 1.0, 0.0, ..., 1, 0, 92888.52],\n",
       "       [1.0, 0.0, 0.0, ..., 1, 0, 38190.78]], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Encoding our categorical variable Geography\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ct =ColumnTransformer(transformers=[('encoder',OneHotEncoder(),[1])],remainder=\"passthrough\")\n",
    "X = np.array(ct.fit_transform(X))\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "ehWfMMLgSg6F"
   },
   "outputs": [],
   "source": [
    "#Splitting dataset into training and testing dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tV4feYGzU8RH"
   },
   "source": [
    "Further, we will perform feature scaling. This can be done in one of two ways\n",
    "* Normalizing\n",
    "* Standardizing\n",
    "\n",
    "Whenever standardization is performed, all values in the dataset will be converted into values ranging between -3 to +3. While in the case of normalization, all values will be converted into a range between -1 to +1.\n",
    "\n",
    "Usually, Normalization is used only when our dataset follows a normal distribution while standardization is a universal technique that can be used for any dataset irrespective of the distribution. Here we are going to use Standardization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "tZTwP3wDVMW3"
   },
   "outputs": [],
   "source": [
    "#Performing Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "g5rWA-hGVPg2"
   },
   "outputs": [],
   "source": [
    "# Initializing Artificial Neural Networks\n",
    "ann = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1RxFmGWnVcpe"
   },
   "source": [
    "Keras which was a separate library in itself is now integrated with tensorflow and is now considered as a sub-library of tensorflow. You can find more about Tensorflow [here.](https://www.tensorflow.org/) \n",
    "\n",
    "</br>\n",
    "\n",
    "Once we initialize our ann, we are now going to create layers for the same. Here we are going to create a network that will have 2 hidden layers, 1 input layer, and 1 output layer. So, let’s create our very first hidden layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "LtVIrmj3Vbsx"
   },
   "outputs": [],
   "source": [
    "#Adding First Hidden Layer\n",
    "ann.add(tf.keras.layers.Dense(units=6,activation=\"relu\")) #Rectified linear unit - activation function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hv9VYAMnWOCq"
   },
   "source": [
    "we have created our first hidden layer by using the Dense class which is part of the layers module. This class accepts 2 inputs:-\n",
    "\n",
    "* units: number of neurons that will be present in the respective layer\n",
    "* activation: specify which activation function to be used\n",
    "\n",
    "Since we are going to create two hidden layers, this same step we are going to repeat for the creation of the second hidden layer as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "u5k9Gx4CWFe4"
   },
   "outputs": [],
   "source": [
    " #Adding Second Hidden Layer\n",
    "ann.add(tf.keras.layers.Dense(units=6,activation=\"relu\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cWNNlyngXIjK"
   },
   "source": [
    "we are now going to create our output layer for ann. The output layer will be responsible for giving output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "pxWxHO_wW1y7"
   },
   "outputs": [],
   "source": [
    "#Adding Output Layer\n",
    "ann.add(tf.keras.layers.Dense(units=1,activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZUncO61DXPRD"
   },
   "source": [
    "In a binary classification problem(like this one) where we will be having only two classes as output (1 and 0), we will be allocating only one neuron to output this result. For the multiclass classification problem, we have to use more than one neuron in the output layer. For example – if our output contains 4 categories then we need to create 4 different neurons(one for each category).\n",
    "\n",
    "For the binary classification problems, the activation function that should always be used is sigmoid. For a multiclass classification problem, the activation function that should be used is softmax.\n",
    "\n",
    "</br>\n",
    "\n",
    "We have now created layers for our neural network. In this step, we are going to compile our ANN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "bjAZSie1XOik"
   },
   "outputs": [],
   "source": [
    "#Compiling ANN\n",
    "ann.compile(optimizer=\"adam\",loss=\"binary_crossentropy\",metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5UcF1rc4YOJC"
   },
   "source": [
    "We have used compile method of our ANN object in order to compile our network. Compile method accepts the below inputs:\n",
    "\n",
    "* optimizer:- specifies which optimizer to be used in order to perform stochastic gradient descent. \n",
    "\n",
    "* loss:- specifies which loss function should be used. For binary classification, the value should be binary_crossentropy. For multiclass classification, it should be categorical_crossentropy.\n",
    "\n",
    "* metrics:- which performance metrics to be used in order to compute performance. Here we have used accuracy as a performance metric.\n",
    "\n",
    "</br>\n",
    "\n",
    "The last step in creating an ANN is to fit our model using the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zIXwLXEyYNNv",
    "outputId": "91fc2134-276f-4870-964e-13ef8c3b7188"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - 2s 2ms/step - loss: 0.5174 - accuracy: 0.7763\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4609 - accuracy: 0.7946\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4454 - accuracy: 0.7971\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4375 - accuracy: 0.8043\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4323 - accuracy: 0.8104\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4277 - accuracy: 0.8109\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4237 - accuracy: 0.8140\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4198 - accuracy: 0.8170\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4163 - accuracy: 0.8199\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4128 - accuracy: 0.8204\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4093 - accuracy: 0.8239\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4067 - accuracy: 0.8279\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4036 - accuracy: 0.8319\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4008 - accuracy: 0.8361\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3977 - accuracy: 0.8351\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3938 - accuracy: 0.8393\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3889 - accuracy: 0.8415\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3844 - accuracy: 0.8444\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3806 - accuracy: 0.8460\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3757 - accuracy: 0.8471\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3717 - accuracy: 0.8491\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3680 - accuracy: 0.8499\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3649 - accuracy: 0.8525\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3614 - accuracy: 0.8535\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3593 - accuracy: 0.8556\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3566 - accuracy: 0.8554\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3542 - accuracy: 0.8553\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3520 - accuracy: 0.8577\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3504 - accuracy: 0.8577\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3486 - accuracy: 0.8586\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3471 - accuracy: 0.8580\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3457 - accuracy: 0.8574\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3445 - accuracy: 0.8587\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3433 - accuracy: 0.8604\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3421 - accuracy: 0.8609\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3414 - accuracy: 0.8621\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3407 - accuracy: 0.8604\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3400 - accuracy: 0.8605\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3392 - accuracy: 0.8610\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3382 - accuracy: 0.8627\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3384 - accuracy: 0.8605\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3376 - accuracy: 0.8625\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3372 - accuracy: 0.8622\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3366 - accuracy: 0.8612\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3370 - accuracy: 0.8604\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3368 - accuracy: 0.8611\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3365 - accuracy: 0.8616\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3358 - accuracy: 0.8606\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3361 - accuracy: 0.8616\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3364 - accuracy: 0.8614\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3354 - accuracy: 0.8622\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3354 - accuracy: 0.8622\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3352 - accuracy: 0.8605\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3358 - accuracy: 0.8621\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3351 - accuracy: 0.8624\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3352 - accuracy: 0.8609\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3347 - accuracy: 0.8639\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3353 - accuracy: 0.8625\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3346 - accuracy: 0.8622\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3348 - accuracy: 0.8630\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3349 - accuracy: 0.8618\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3345 - accuracy: 0.8624\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3342 - accuracy: 0.8626\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3345 - accuracy: 0.8626\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3342 - accuracy: 0.8626\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3346 - accuracy: 0.8614\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3339 - accuracy: 0.8618\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3343 - accuracy: 0.8629\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3341 - accuracy: 0.8630\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3339 - accuracy: 0.8629\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3334 - accuracy: 0.8614\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3337 - accuracy: 0.8619\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3336 - accuracy: 0.8633\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3337 - accuracy: 0.8630\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3332 - accuracy: 0.8636\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3334 - accuracy: 0.8609\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3336 - accuracy: 0.8629\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3329 - accuracy: 0.8622\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3331 - accuracy: 0.8631\n",
      "Epoch 80/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3328 - accuracy: 0.8629\n",
      "Epoch 81/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3327 - accuracy: 0.8635\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3324 - accuracy: 0.8620\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3324 - accuracy: 0.8621\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3321 - accuracy: 0.8622\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3325 - accuracy: 0.8629\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3325 - accuracy: 0.8627\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3322 - accuracy: 0.8622\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3316 - accuracy: 0.8629\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3319 - accuracy: 0.8624\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3318 - accuracy: 0.8631\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3316 - accuracy: 0.8640\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3312 - accuracy: 0.8612\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3313 - accuracy: 0.8636\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3310 - accuracy: 0.8634\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3311 - accuracy: 0.8635\n",
      "Epoch 96/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3312 - accuracy: 0.8639\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3312 - accuracy: 0.8620\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3308 - accuracy: 0.8634\n",
      "Epoch 99/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3308 - accuracy: 0.8634\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3309 - accuracy: 0.8626\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff911843310>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fitting ANN\n",
    "ann.fit(X_train,Y_train,batch_size=32,epochs = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eL2dKZ0uZuOd"
   },
   "source": [
    "Here we have used the fit method in order to train our ann. The fit method is accepting 4 inputs in this case:-\n",
    "\n",
    "* X_train: Matrix of features for the training dataset\n",
    "* Y_train: Dependent variable vectors for the training dataset\n",
    "* batch_size: how many observations should be there in the batch. Usually, the value for this parameter is 32 but we can experiment with any other value as well.\n",
    "* epochs: How many times neural networks will be trained. Here the optimal value that I have found from my experience is 100.\n",
    "\n",
    "</br>\n",
    "\n",
    "Here we can see that in each epoch our loss is decreasing and our accuracy is increasing. As we can see here that our final accuracy is 86.59 which is pretty remarkable for a neural network with this simplicity.\n",
    "\n",
    "</br>\n",
    "\n",
    "To create single-point predict for custom values, we can use the following code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L9EcEgCVYuE1",
    "outputId": "7bb4d967-3a96-4b02-a19f-8c6542d6e1d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[False]]\n"
     ]
    }
   ],
   "source": [
    "#Predicting result for Single Observation\n",
    "print(ann.predict(sc.transform([[1, 0, 0, 600, 1, 40, 3, 60000, 2, 1, 1,50000]])) > 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m15IdlsqaegU"
   },
   "source": [
    "Here our neural network is trying to predict whether our customer is going to exit or not based on the values of independent variables"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ANN for Classification Problems.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
